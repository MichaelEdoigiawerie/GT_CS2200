CS 2200 Fall 2023
Project 4

Name: Michael Edoigiawerie
GT Username: medoigiawerie3

6.1 FIFO Scheduler
Run your OS simulation with 1, 2, and 4 CPUs. Compare the total execution time of each. Is there a linear relationship between the number of CPUs and total execution time? Why or why not? Keep in mind that the execution time refers to the simulated execution time.
----------

There is no linear relationship between them because the change in total execution time during each OS simulation
isn't constant. According to the data collected, the difference between the 1-CPU-simulation and the 2-CPU-simulation
is drastically larger than the difference between the 2-CPU-simulation and the 4-CPU simulation. The drastic difference
between 1 CPU and 2 CPUs is due to the high CPU utilization for 2 CPUs compared to just 1 CPU. However, the minimal difference
in 2 CPUs and 4 CPUs is caused by the amount of time waiting for a process to become available again.

Data collected:
- Number of CPUs: 1; Total Execution Time: 67.9 seconds.
- Number of CPUs: 2; Total Execution Time: 39.8 seconds.
- Number of CPUs: 4; Total Execution Time: 37.0 seconds.

6.2 Round-Robin Scheduler
Run your Round-Robin scheduler with timeslices of 800ms, 600ms, 400ms, and 200ms. Use only one CPU
for your tests. Compare the statistics at the end of the simulation. Is there a relationship between the total waiting time and timeslice length? If so, what is it? In contrast, in a real OS, the shortest timeslice possible is usually not the best choice. Why not?
----------

There is a linear relationship between the total waiting time and the timeslice length.
As the timeslice length of the scheduler decreases, the total waiting time also decreases, and vice versa.

Data collected:
- Timeslice Length: 800ms; Total Waiting Time: 317.1 seconds
- Timeslice Length: 600ms; Total Waiting Time: 302.3 seconds
- Timeslice Length: 400ms; Total Waiting Time: 291.7 seconds
- Timeslice Length: 200ms; Total Waiting Time: 284.4 seconds

The shortest timeslice possible isn't usually the best choice for real OSs because the cost of restarting
processes and context switching could be more expensive than the amount of time that was saved by reducing
the waiting time within each process as a result of having the shortest possible timeslice.

6.3 Preemptive Priority Scheduler
Priority schedulers can sometimes lead to starvation among processes with lower priority. What is a way
that operating systems can mitigate starvation in a priority scheduler?
----------

A good way to mitigate starvation among processes with lower priority is to gradually increase the priority of a
process as they age. This is done by tracking how long a lower priority process has stayed on the ready queue. 
This way, you can find the lowest priority process currently running on the CPU (since the processes running on the
CPU have a constant initial priority level) and preempt that process so that the lower priority process on the 
ready queue can be dispatched. 

6.4 Priority Inversion
Consider a non-preemptive priority scheduler. Suppose you have a high-priority process (P1) that wants to display a window on the monitor. But, the window manager is a process with low priority and will be placed at the end of the ready queue. While it is waiting to be scheduled, new medium-priority processes are likely to come in and starve the window manager process. The starvation of the window manager will also mean the starvation of P1 (the process with high priority), since P1 is waiting for the window manager to finish running. 

If we want to keep our non-preemptive priority scheduler, what edits can we make to our scheduler to ensure that the P1 can finish its execution before any of the medium priority processes finish their execution? Explain in detail the changes you would make.
----------

One possible way we can ensure the completion of P1 is to find the total number of dependecies a process has 
because something as complex as a window manager has to rely on a lot of software components. This would allow our
low-priority process (the window manager) to have a higher priority than the new medium-priority processes.

However, because of this modification, some processes might not get to run because they have very little or no
dependecies. To account for this issue, we could determine the priority level of each process by the finding the
average number of dependecies per priority level. This can be done by dividing the total number of dependecies for
each process by the initial priority level of said process (1, 2, 3, etc.).

